{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6086a1e-b1e4-416a-91fe-3bc36e47ae35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the encoding to avoid UnicodeDecodeError\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('spam.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "908f7c07-5826-483f-95f5-1894d39d6fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bfc1536-3e2a-41f0-bf18-584f68b1264b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   v1          5572 non-null   object\n",
      " 1   v2          5572 non-null   object\n",
      " 2   Unnamed: 2  50 non-null     object\n",
      " 3   Unnamed: 3  12 non-null     object\n",
      " 4   Unnamed: 4  6 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 217.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "162163a3-4ff2-4689-bec4-51ca21291cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2697f241-d419-4189-b62f-d716bd50e348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                               text Unnamed: 2  \\\n",
       "0    ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1    ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3    ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4    ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# renaming the cols\n",
    "df.rename(columns={'v1':'target','v2':'text'},inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd3511e4-64e9-48ac-b8f5-40fc52d0c173",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = encoder.fit_transform(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b91b9562-b36e-4419-8ffd-0da5e497501f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop last 3 cols\n",
    "df.drop(columns=['Unnamed: 2','Unnamed: 3','Unnamed: 4'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4bd0b59-36d6-4748-a53f-308256a53eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       0  Go until jurong point, crazy.. Available only ...\n",
       "1       0                      Ok lar... Joking wif u oni...\n",
       "2       1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       0  U dun say so early hor... U c already then say...\n",
       "4       0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8408dcef-6b7c-4012-b202-e0a7864c5392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "392c5add-c107-43f6-9539-13cd0b4bacda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for duplicate values\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edd30317-e9f3-4808-b582-39929bd1c2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "df = df.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8622627-1942-4e22-9854-b2efae7d0bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc0086f7-82cd-4218-8497-e1e4997d1c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5169, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "631fa932-f825-4b2f-af1e-becd0e571283",
   "metadata": {},
   "source": [
    "3. Data Preprocessing\n",
    "Lower case\n",
    "Tokenization\n",
    "Removing special characters\n",
    "Removing stop words and punctuation\n",
    "Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e7e4a5a-4f2d-4800-ba2b-09e4211eec75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\91915\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\91915\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "\n",
    "# Ensure you have downloaded the necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def transform_text(text):\n",
    "    # Initialize the Porter Stemmer\n",
    "    ps = PorterStemmer()\n",
    "    \n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize the text\n",
    "    text = word_tokenize(text)\n",
    "    \n",
    "    # Filter out non-alphanumeric tokens\n",
    "    y = [i for i in text if i.isalnum()]\n",
    "    \n",
    "    # Remove stopwords and punctuation\n",
    "    y = [i for i in y if i not in stopwords.words('english')]\n",
    "\n",
    "    # Stem the remaining words\n",
    "    y = [ps.stem(i) for i in y]\n",
    "    \n",
    "    return \" \".join(y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "345485b7-d0dd-4a78-adab-5ad351c1eb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gon na home soon want talk stuff anymor tonight k cri enough today\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "result = transform_text(\"I'm gonna be home soon and I don't want to talk about this stuff anymore tonight, k? I've cried enough today.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ad87c6a-47d1-4fc5-8419-a33f21fa74dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75a937d6-a2fc-4b31-9909-0a7f2cc7cd45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'love'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "ps.stem('loving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8914c08-0aa4-4df5-a573-6e5cb7458f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['transformed_text'] = df['text'].apply(transform_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3465cb2d-c965-4dad-a9ac-0a1a71f1b43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>transformed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazi avail bugi n great world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkt 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say earli hor u c alreadi say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah think goe usf live around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text  \\\n",
       "0       0  Go until jurong point, crazy.. Available only ...   \n",
       "1       0                      Ok lar... Joking wif u oni...   \n",
       "2       1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3       0  U dun say so early hor... U c already then say...   \n",
       "4       0  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                    transformed_text  \n",
       "0  go jurong point crazi avail bugi n great world...  \n",
       "1                              ok lar joke wif u oni  \n",
       "2  free entri 2 wkli comp win fa cup final tkt 21...  \n",
       "3                u dun say earli hor u c alreadi say  \n",
       "4               nah think goe usf live around though  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ef518af-4f41-43be-8880-5d8a3f373bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5169 entries, 0 to 5571\n",
      "Data columns (total 3 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   target            5169 non-null   int32 \n",
      " 1   text              5169 non-null   object\n",
      " 2   transformed_text  5169 non-null   object\n",
      "dtypes: int32(1), object(2)\n",
      "memory usage: 270.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ff8e85-6195-425f-a598-15785b2cd8e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "571f2a0d-bf77-4816-bf3e-c075933e616e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.preprocessing.text.Tokenizer at 0x20bf7527390>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set parameters for tokenization and padding\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Embedding, Dropout\n",
    "vocab_size = 5000  # Number of unique words to keep\n",
    "max_length = 100   # Maximum length of each input sequence\n",
    "\n",
    "# Initialize and fit the tokenizer on the transformed text column\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1d08dd8-21ba-4c10-beb0-f169e6aa8f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(df['transformed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7abb1dd6-9e6e-4721-ba33-817733c96577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.preprocessing.text.Tokenizer at 0x20bf7527390>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db7820b1-07db-40aa-84ba-3f653f056aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert texts to sequences\n",
    "X = tokenizer.texts_to_sequences(df['transformed_text'])\n",
    "X = pad_sequences(X, maxlen=max_length)\n",
    "\n",
    "# Labels\n",
    "y = df['target'].values\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0a95d336-83c1-4487-bc92-1804f330cf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Build the Model\n",
    "model = Sequential()\n",
    "\n",
    "# Embedding layer\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_length))\n",
    "\n",
    "# CNN layer\n",
    "model.add(Conv1D(filters=64, kernel_size=2, activation='relu'))\n",
    "\n",
    "# LSTM layer\n",
    "model.add(LSTM(88, return_sequences=True))\n",
    "model.add(Dropout(0.3))  # Dropout for regularization\n",
    "\n",
    "# Second LSTM layer\n",
    "model.add(LSTM(44))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation='sigmoid'))  # Sigmoid activation for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "71fc0bc5-c916-42b4-809b-743d76dc58e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "130/130 [==============================] - 32s 247ms/step - loss: 0.0386 - accuracy: 0.9911 - val_loss: 0.0720 - val_accuracy: 0.9807\n",
      "Epoch 2/2\n",
      "130/130 [==============================] - 32s 245ms/step - loss: 0.0148 - accuracy: 0.9966 - val_loss: 0.0769 - val_accuracy: 0.9826\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Train the Model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "728a7c0d-3e56-4adc-940b-7a7cac439100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 2s 65ms/step - loss: 0.0769 - accuracy: 0.9826\n",
      "Test Accuracy: 98.26%\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Evaluate the Model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d789b3cd-eab0-48fa-840d-f7fddea117ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "613e3cda-71ea-4bac-b848-3165311a4d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model,open('model2.pkl','wb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "71db3256-ab6a-40ef-82db-1814559b12c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "793e3922-b041-4582-b9e9-367b8d248d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tokenizer,open('tokenizer.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
